{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "612b16bf",
   "metadata": {},
   "source": [
    "# 자연어 처리 NLP (Natural Language Processing) | 텍스트 분석 Text Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8d357",
   "metadata": {},
   "source": [
    "- 자연어 처리: 사람이 사용하는 언어 전반에 대해서 이해하고 처리하는 분야\n",
    "    - 음성인식, 번역, 감정분석, 질의응답, 언어 생성 등 포괄적 분야\n",
    "- 텍스트 분석: 언어적 비정형 데이터에서 정보를 추출하고 분석하는 작업\n",
    "    - 텍스트 통계적 분석, 주제 분류, 텍스트 군집, 유사도 분석 등"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f9c46a",
   "metadata": {},
   "source": [
    "### 파이썬 텍스트분석 패키지 \n",
    "\n",
    "| **로고 이미지**                                                                                                 | **패키지**   | **설명**                                            | **주요 특징 및 기능**                                                   | **API 문서 URL**                                  |\n",
    "|------------------------------------------------------------------------------------------------------------|--------------|---------------------------------------------------|-----------------------------------------------------------------------|-------------------------------------------------|\n",
    "| ![nltk](https://d.pr/i/9xVzCK+)                   | **nltk**     | 가장 오래된 NLP 라이브러리 중 하나로, 다양한 자연어 처리 도구와 코퍼스 제공 | 토큰화, 품사 태깅, 어간 추출, 불용어 제거, 문법 구조 분석, 감정 분석 등에 유용 | [NLTK API Docs](https://www.nltk.org/api/nltk.html) |\n",
    "| ![gensim](https://radimrehurek.com/gensim/_static/images/gensim.png)                                       | **gensim**   | 주로 텍스트의 토픽 모델링과 문서 유사도 분석을 위한 라이브러리            | Word2Vec, FastText, LDA, 유사도 측정, 대용량 텍스트 처리에 최적화    | [Gensim API Docs](https://radimrehurek.com/gensim/) |\n",
    "| ![spacy](https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/SpaCy_logo.svg/320px-SpaCy_logo.svg.png) | **spacy**    | 빠르고 효율적인 NLP 처리를 위해 개발된 라이브러리로, 산업용 프로젝트에 적합     | 빠른 토큰화, 품사 태깅, NER, 구문 분석, 벡터 표현 제공              | [SpaCy API Docs](https://spacy.io/api)             |\n",
    "| ![TextBlob](https://textblob.readthedocs.io/en/dev/_static/textblob-logo.png)                              | **TextBlob** | 간단한 NLP 작업을 위한 라이브러리로, 감정 분석과 텍스트 정제 등 지원  | 문법 교정, 감정 분석, 텍스트 번역 등과 같은 간단한 작업에 적합      | [TextBlob API Docs](https://textblob.readthedocs.io/en/dev/) |\n",
    "| ![KoNLPy](https://konlpy.org/en/latest/_static/konlpy.png)                                                 | **KoNLPy**   | 한국어 자연어 처리를 위한 라이브러리로, 여러 형태소 분석기를 제공          | Kkma, Hannanum, Komoran, Twitter, Mecab 형태소 분석기 지원            | [KoNLPy API Docs](https://konlpy.org/en/latest/)  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05219e9f",
   "metadata": {},
   "source": [
    "### NLTK (Natural Language Toolkit)\n",
    "- 파이썬에서 텍스트 처리 및 자연어 처리를 쉽게 다룰 수 있게 해주는 오픈 소스 라이브러리\n",
    "- NLTK는 다양한 언어 리소스와 알고리즘을 포함하고 있으며, 텍스트 마이닝, 텍스트 분석, 그리고 자연어 처리를 공부하거나 구현할 때 유용\n",
    "\n",
    "**주요 기능**\n",
    "1. **토큰화(Tokenization)**: 문장을 단어 또는 문장 단위로 나누는 작업\n",
    "    - 예를 들어, `\"I love NLP.\"`를 `['I', 'love', 'NLP', '.']`와 같이 나누는 기능을 제공한다.\n",
    "2. **품사 태깅(Part-of-Speech Tagging)**: 각 단어에 대해 해당 품사를 태깅하는 작업\n",
    "    - 예를 들어, `\"I love NLP.\"`에 대해 `[('I', 'PRP'), ('love', 'VBP'), ('NLP', 'NNP'), ('.', '.')]`와 같이 태깅한다.\n",
    "3. **명사구 추출(Chunking)**: 문장에서 명사구와 같은 특정 구문을 추출하는 작업\n",
    "4. **어근 추출(Lemmatization) 및 어간 추출(Stemming)**: 단어의 기본 형태를 찾는 작업으로, 동사의 기본형을 찾거나 복수형을 단수형으로 변환하는 등의 작업 수행\n",
    "5. **텍스트 분류(Classification)**: Naive Bayes, MaxEnt 등의 분류 모델을 사용해 텍스트 분류 가능\n",
    "6. **코퍼스(corpus) 제공**: 영화 리뷰, 뉴스 기사 등 여러 텍스트 데이터셋을 포함하고 있어 학습과 실습에 유용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c824c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 channel Terms of Service accepted\n",
      "Retrieving notices: done\n",
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\Users\\Playdata\\anaconda3\\envs\\ml_env\n",
      "\n",
      "  added / updated specs:\n",
      "    - nltk\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.9.9   |       haa95532_0         127 KB\n",
      "    click-8.2.1                |  py312haa95532_0         329 KB\n",
      "    colorama-0.4.6             |  py312haa95532_0          53 KB\n",
      "    joblib-1.5.2               |  py312haa95532_0         517 KB\n",
      "    nltk-3.9.1                 |  py312haa95532_0         2.7 MB\n",
      "    openssl-3.0.18             |       h543e019_0         6.8 MB\n",
      "    regex-2025.9.1             |  py312h02ab6af_0         364 KB\n",
      "    tqdm-4.67.1                |  py312hfc267ef_0         187 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.1 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  click              pkgs/main/win-64::click-8.2.1-py312haa95532_0 \n",
      "  colorama           pkgs/main/win-64::colorama-0.4.6-py312haa95532_0 \n",
      "  joblib             pkgs/main/win-64::joblib-1.5.2-py312haa95532_0 \n",
      "  nltk               pkgs/main/win-64::nltk-3.9.1-py312haa95532_0 \n",
      "  regex              pkgs/main/win-64::regex-2025.9.1-py312h02ab6af_0 \n",
      "  tqdm               pkgs/main/win-64::tqdm-4.67.1-py312hfc267ef_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates                      2025.7.15-haa95532_0 --> 2025.9.9-haa95532_0 \n",
      "  openssl                                 3.0.17-h35632f6_0 --> 3.0.18-h543e019_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages: ...working...\n",
      "openssl-3.0.18       | 6.8 MB    |            |   0% \n",
      "\n",
      "nltk-3.9.1           | 2.7 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 517 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regex-2025.9.1       | 364 KB    |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.2.1          | 329 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.67.1          | 187 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 53 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "nltk-3.9.1           | 2.7 MB    |            |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.2.1          | 329 KB    | 4          |   5% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 517 KB    | 3          |   3% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regex-2025.9.1       | 364 KB    | 4          |   4% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.2.1          | 329 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 517 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "openssl-3.0.18       | 6.8 MB    |            |   0% \n",
      "\n",
      "\n",
      "\n",
      "regex-2025.9.1       | 364 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "nltk-3.9.1           | 2.7 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.67.1          | 187 KB    | 8          |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | #2         |  13% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.67.1          | 187 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 53 KB     | ###        |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 53 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "regex-2025.9.1       | 364 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "openssl-3.0.18       | 6.8 MB    | ###4       |  34% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.2.1          | 329 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "click-8.2.1          | 329 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "openssl-3.0.18       | 6.8 MB    | #########2 |  92% \n",
      "openssl-3.0.18       | 6.8 MB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.67.1          | 187 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "tqdm-4.67.1          | 187 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 517 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "joblib-1.5.2         | 517 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2025 | 127 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 53 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "colorama-0.4.6       | 53 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "openssl-3.0.18       | 6.8 MB    | ########## | 100% \n",
      "\n",
      "nltk-3.9.1           | 2.7 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "nltk-3.9.1           | 2.7 MB    | ########## | 100% \u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "    current version: 25.5.1\n",
      "    latest version: 25.9.1\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install nltk -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b59e0ea0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.9.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceac9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk 리소스 다운로드\n",
    "nltk.download('punkt')       # 토큰화에 필요한 데이터\n",
    "nltk.download('punkt_tab')   #\n",
    "nltk.download('stopwords')   # 불용어 리스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d11f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLTK',\n",
       " 'is',\n",
       " 'a',\n",
       " 'powerful',\n",
       " 'library',\n",
       " 'for',\n",
       " 'NLP',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '!',\n",
       " '!']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "text = 'NLTK is a powerful library for NLP!!!!!'\n",
    "word_tokenize(text)    # 단어 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a872015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Playdata\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 감성분석\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8eb47a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.259, 'pos': 0.741, 'compound': 0.8619}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentimetIntensityAnalyzer를 통한 감성분석\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "# vader 는 감정에 대한 사전이 있다. 그래서 그 감정에 대해서 점수를 환산한다.\n",
    "# SentimentIntensityAnalyzer.polarity_scores(corpus)\n",
    "# - neg 부정(0 ~ 1)\n",
    "# - neu 중립(0 ~ 1)\n",
    "# - pos 긍정(0 ~ 1)\n",
    "# - compound 복합(-1 ~ 1)\n",
    "\n",
    "analyser.polarity_scores(\"I love this product! It's amazing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81251161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.6369}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.polarity_scores(\"Love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b206a4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5106}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.polarity_scores(\"Ugly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "553ec924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.4215}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.polarity_scores(\"Satisfied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "87e0300c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.5994}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.polarity_scores(\"Death\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87355115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyser.polarity_scores(\"soso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b515d836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I absolutely love this! | {'neg': 0.0, 'neu': 0.295, 'pos': 0.705, 'compound': 0.6989}\n",
      "This is okay, I guess | {'neg': 0.0, 'neu': 0.612, 'pos': 0.388, 'compound': 0.2263}\n",
      "I hate it so much | {'neg': 0.552, 'neu': 0.448, 'pos': 0.0, 'compound': -0.5719}\n"
     ]
    }
   ],
   "source": [
    "texts = ['I absolutely love this!',\n",
    "         'This is okay, I guess',\n",
    "         'I hate it so much'\n",
    "         ]\n",
    "\n",
    "for text in texts:\n",
    "    score = analyser.polarity_scores(text)\n",
    "    print(f'{text} | {score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3da1829",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
