{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e1d2317",
   "metadata": {},
   "source": [
    "# Subword Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b40fb1",
   "metadata": {},
   "source": [
    "| **Tokenizer 방식** | **토큰 단위**                      | **vocab size** | **미등록 단어에 대한 가정**                                                                                  |\n",
    "|---------------------|------------------------------------|----------------|-------------------------------------------------------------------------------------------------------------|\n",
    "| **사전 기반**       | 알려진 단어/형태소의 결합           | unlimited       | - 알려진 단어/형태소의 결합이라고 가정<br>- 필요한 형태소 분석 가능<br>- 사전에 등록되지 않은 단어는 UNK 처리 |\n",
    "| **sub-word**        | 알려진 글자 및 sub-word            | fixed           | - 알려진 sub-words로 분해<br>- 예: appear → app + ear<br>- 자주 등장하는 단어를 제대로 인식 가능<br>- UNK의 개수 최소화 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4245aaaf",
   "metadata": {},
   "source": [
    "(memo)...\n",
    "\n",
    "**WordPiece** : 구글에서 개발한 토크나이저, BERT 모델에서 사용\n",
    "→ 확률기반\n",
    "Pairs scores 높은 조합을 확률로 서브워드로 나눠 높은 빈도를 가진 확률로 뭉쳐있는 것들로 vocab\n",
    "\n",
    "**BPE(Byte Pair Encoding)**: 빈도를 기반으로 문자 쌍을 반복적으로 병합\n",
    "\n",
    "WordPiece, BPE는 단어의 경계를 고려하지만, SentencePiece는 고려하지 않는다.\n",
    "\n",
    "**SentencePiece**: 구글에서 개발한 언어 독립적인 토크나이저\n",
    "BPE, Unigram Languae Model 두 가지 알고리즘을 지원\n",
    "유니코드 문자를 직접 처리, 공백도 하나의 심볼로 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66f05c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08dd1836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네이버 영화 리뷰데이터\n",
    "\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "def get_file(filename, origin):\n",
    "    cache_dir = os.path.expanduser('~/.torch/datasets')\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    filepath = os.path.join(cache_dir, filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f'Downloading data from {origin}')\n",
    "        urllib.request.urlretrieve(origin, filepath)\n",
    "\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a44ec1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\Playdata/.torch/datasets\\\\ratings_train.txt',\n",
       " 'C:\\\\Users\\\\Playdata/.torch/datasets\\\\ratings_test.txt')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train_path = get_file(\"ratings_train.txt\", \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\")\n",
    "ratings_test_path = get_file(\"ratings_test.txt\", \"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\")\n",
    "\n",
    "ratings_train_path, ratings_test_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0fa3a6c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149995</th>\n",
       "      <td>6222902</td>\n",
       "      <td>인간이 문제지.. 소는 뭔죄인가..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149996</th>\n",
       "      <td>8549745</td>\n",
       "      <td>평점이 너무 낮아서...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149997</th>\n",
       "      <td>9311800</td>\n",
       "      <td>이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149998</th>\n",
       "      <td>2376369</td>\n",
       "      <td>청춘 영화의 최고봉.방황과 우울했던 날들의 자화상</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149999</th>\n",
       "      <td>9619869</td>\n",
       "      <td>한국 영화 최초로 수간하는 내용이 담긴 영화</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                                           document  label\n",
       "0        9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1        3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2       10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3        9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4        6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "...          ...                                                ...    ...\n",
       "149995   6222902                                인간이 문제지.. 소는 뭔죄인가..      0\n",
       "149996   8549745                                      평점이 너무 낮아서...      1\n",
       "149997   9311800                    이게 뭐요? 한국인은 거들먹거리고 필리핀 혼혈은 착하다?      0\n",
       "149998   2376369                        청춘 영화의 최고봉.방황과 우울했던 날들의 자화상      1\n",
       "149999   9619869                           한국 영화 최초로 수간하는 내용이 담긴 영화      0\n",
       "\n",
       "[150000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4608761</td>\n",
       "      <td>오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>5308387</td>\n",
       "      <td>의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>9072549</td>\n",
       "      <td>그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>5802125</td>\n",
       "      <td>절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>6070594</td>\n",
       "      <td>마무리는 또 왜이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                           document  label\n",
       "0      6270596                                                굳 ㅋ      1\n",
       "1      9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2      8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3      6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4      6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0\n",
       "...        ...                                                ...    ...\n",
       "49995  4608761          오랜만에 평점 로긴했네ㅋㅋ 킹왕짱 쌈뽕한 영화를 만났습니다 강렬하게 육쾌함      1\n",
       "49996  5308387       의지 박약들이나 하는거다 탈영은 일단 주인공 김대희 닮았고 이등병 찐따 OOOO      0\n",
       "49997  9072549                 그림도 좋고 완성도도 높았지만... 보는 내내 불안하게 만든다      0\n",
       "49998  5802125     절대 봐서는 안 될 영화.. 재미도 없고 기분만 잡치고.. 한 세트장에서 다 해먹네      0\n",
       "49999  6070594                                         마무리는 또 왜이래      0\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings_train_df = pd.read_csv(ratings_train_path, sep=\"\\t\")\n",
    "ratings_test_df = pd.read_csv(ratings_test_path, sep=\"\\t\")\n",
    "\n",
    "display(ratings_train_df)\n",
    "display(ratings_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c57b1d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          0\n",
       "document    5\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train_df.isna().sum()    # train : 5, test : 3 → 결측치 확인함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "174e19c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150000, 3), (50000, 3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings_train_df.shape, ratings_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c764117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((149995, 3), (49997, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "ratings_train_df = ratings_train_df.dropna(how='any')\n",
    "ratings_test_df = ratings_test_df.dropna(how='any')\n",
    "\n",
    "ratings_train_df.shape, ratings_test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df956e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# txt 파일 생성 - 학습 데이터\n",
    "\n",
    "with open('naver_review.txt', 'w', encoding='UTF-8') as f:\n",
    "    for doc in ratings_train_df['document'].values:\n",
    "        f.write(doc + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bc4138",
   "metadata": {},
   "source": [
    "### SentencePieceTokenizer *제일 유용*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2868b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 52.8 MB/s  0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install sentencepiece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193247c2",
   "metadata": {},
   "source": [
    "(memo)...\n",
    "sentencepiece 는 C++ 기반으로 만들어져있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5faca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as stp\n",
    "\n",
    "input = 'naver_review.txt'\n",
    "vocab_size = 10000\n",
    "model_prefix = 'naver_review'\n",
    "cmd = f'--input={input} --model_prefix={model_prefix} --vocab_size={vocab_size}'\n",
    "\n",
    "stp.SentencePieceTrainer.Train(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c92cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "아 더빙.. 진짜 짜증나네요 목소리\n",
      "['▁아', '▁더빙', '..', '▁진짜', '▁짜증나', '네요', '▁목소리']\n",
      "[62, 877, 5, 31, 2019, 68, 1710]\n",
      "\n",
      "흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\n",
      "['▁흠', '...', '포스터', '보고', '▁초딩', '영화', '줄', '....', '오', '버', '연기', '조차', '▁가볍지', '▁않', '구나']\n",
      "[1634, 8, 4908, 159, 1460, 33, 264, 60, 173, 548, 410, 1224, 7396, 754, 440]\n",
      "\n",
      "너무재밓었다그래서보는것을추천한다\n",
      "['▁너무', '재', '밓', '었다', '그래서', '보', '는것을', '추천', '한다']\n",
      "[23, 369, 9781, 429, 3780, 143, 6266, 1945, 314]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sp = stp.SentencePieceProcessor()\n",
    "sp.Load(f'{model_prefix}.model')       # 토크나이저 모델 로드\n",
    "\n",
    "for doc in ratings_train_df['document'].values[:3]:\n",
    "    print(doc)\n",
    "    print(sp.encode_as_pieces(doc))    # 토큰화 → SentencePiece를 활용한 토큰화\n",
    "    print(sp.encode_as_ids(doc))       # 시퀀싱 → 토큰화 후 정수 인코딩\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8119ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어사전/ 모델의 어휘 크기(vocabulary size) 출력\n",
    "sp.get_piece_size()    # 10000\n",
    "# sp.GetPieceSize()    # 10000 → vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e93beae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "걸작은 몇안되고 졸작들만 넘쳐난다.\n",
      "['▁걸작', '은', '▁몇', '안되고', '▁졸작', '들만', '▁넘', '쳐', '난다', '.']\n",
      "[1060, 18, 621, 6979, 728, 3291, 165, 705, 1003, 4]\n",
      "걸작은 몇안되고 졸작들만 넘쳐난다.\n",
      "걸작은 몇안되고 졸작들만 넘쳐난다.\n",
      "걸작은 몇안되고 졸작들만 넘쳐난다.\n"
     ]
    }
   ],
   "source": [
    "# 인코딩\n",
    "text = ratings_test_df['document'][100]\n",
    "tokens = sp.encode_as_pieces(text)       # 텍스트 → subword 단위 분할\n",
    "id_tokens = sp.encode_as_ids(text)       # 텍스트 → subword 단위 분할 → 고유 ID 변환\n",
    "\n",
    "# 토큰화 결과 확인\n",
    "print(text)\n",
    "print(tokens)\n",
    "print(id_tokens)\n",
    "\n",
    "# 디코딩\n",
    "print(\"\".join(tokens).replace(\"▁\", \" \").strip())\n",
    "print(sp.decode_pieces(tokens))\n",
    "print(sp.decode_ids(id_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30cbff1",
   "metadata": {},
   "source": [
    "### BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ce518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tokenizers in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (0.22.1)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from tokenizers) (0.35.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.15.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<2.0,>=0.16.4->tokenizers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\playdata\\anaconda3\\envs\\ml_env\\lib\\site-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.8.3)\n"
     ]
    }
   ],
   "source": [
    "# !pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "85324804",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenizers import BertWordPieceTokenizer\n",
    "\n",
    "tokenizer = BertWordPieceTokenizer(\n",
    "    lowercase=False,              # 소문자로 토큰 관리 X / 한국어는 대소문자가 없음\n",
    "    strip_accents=False,          # 발음 강세문자 기호 제거 X / 한국어에는 자모 분리 가능성\n",
    ")\n",
    "vocab_size = 10000\n",
    "\n",
    "tokenizer.train(\n",
    "    files=['naver_review.txt'],  # 토크나이징 할 파일 경로\n",
    "    vocab_size=vocab_size,       # 어휘 크기\n",
    "    min_frequency=5,             # 최소 빈도 → 빈도가 5 이상인 토큰만 포함해서 단어 사전에 포함\n",
    "    show_progress=True,          # 진행 표시\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78f5e29c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./bert_word_piece_from_naver_review-vocab.txt']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_model('./', 'bert_word_piece_from_naver_review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7357c500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding(num_tokens=9, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
      "['걸작', '##은', '몇', '##안되고', '졸작', '##들만', '넘쳐', '##난다', '.']\n",
      "[2759, 1086, 445, 9499, 2589, 3799, 8337, 2430, 16]\n",
      "걸작은 몇안되고 졸작들만 넘쳐난다.\n"
     ]
    }
   ],
   "source": [
    "text = ratings_test_df['document'][100]\n",
    "encoded = tokenizer.encode(text)\n",
    "\n",
    "print(encoded)\n",
    "print(encoded.tokens)\n",
    "print(encoded.ids)\n",
    "\n",
    "print(tokenizer.decode(encoded.ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321e431",
   "metadata": {},
   "source": [
    "##### 결과 비교 : SentencePieceTokenizer | BertWordPieceTokenizer\n",
    "\n",
    "```python\n",
    " # SentencePieceTokenizer 토크나이저 결과\n",
    "\n",
    " 걸작은 몇안되고 졸작들만 넘쳐난다.\n",
    " ['▁걸작', '은', '▁몇', '안되고', '▁졸작', '들만', '▁넘', '쳐', '난다', '.']\n",
    " [1060, 18, 621, 6979, 728, 3291, 165, 705, 1003, 4]\n",
    " 걸작은 몇안되고 졸작들만 넘쳐난다.\n",
    " ```\n",
    "\n",
    "```python\n",
    " # BertWordPieceTokenizer 토크나이저 결과\n",
    "\n",
    " ['걸작', '##은', '몇', '##안되고', '졸작', '##들만', '넘쳐', '##난다', '.']\n",
    " [2759, 1086, 445, 9499, 2589, 3799, 8337, 2430, 16]\n",
    " 걸작은 몇안되고 졸작들만 넘쳐난다.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2965dbf",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a158895",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 전처리 연습\n",
    "docstring = \"\"\"\n",
    "1. 적절한 데이터셋을 찾거나 생성한다.\n",
    "2. 적절한 전처리를 진행한다.\n",
    "3. TfidfVectorizer를 활용해 문서를 백터화한다.\n",
    "4. Cosine Similarity를 계산하여 입력된 문자열의 긍/부정 여부를 판단한다. \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
