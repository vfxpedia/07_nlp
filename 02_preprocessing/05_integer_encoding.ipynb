{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0052d0fd",
   "metadata": {},
   "source": [
    "# 정수 인코딩 (Integer Encoding)\n",
    "\n",
    "- 자연어 처리는 텍스트 데이터를 숫자로 변환하여 컴퓨터가 이해할 수 있도록 만드는 것이 핵심\n",
    "- 정수 인코딩을 수행하여 텍스트 데이터에 고유한 인덱스를 부여\n",
    "- 이러한 인코딩 과정은 전처리 과정에서 필수적이며 각 단어의 등장 빈도에 따라 인덱스를 부여하는 것이 일반적\n",
    "- 단어 수를 5,000으로 제한하는 것은 모델 학습에 필요한 메모리와 계산 자원을 줄이기 위함 (등장 빈도가 낮은 단어는 제외하고 상위 5,000개 단어만 선택하는 것이 일반적)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "52bb007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"The Little Prince, written by Antoine de Saint-Exupéry, is a poetic tale about a young prince who travels from his home planet to Earth. The story begins with a pilot stranded in the Sahara Desert after his plane crashes. While trying to fix his plane, he meets a mysterious young boy, the Little Prince.\n",
    "\n",
    "The Little Prince comes from a small asteroid called B-612, where he lives alone with a rose that he loves deeply. He recounts his journey to the pilot, describing his visits to several other planets. Each planet is inhabited by a different character, such as a king, a vain man, a drunkard, a businessman, a geographer, and a fox. Through these encounters, the Prince learns valuable lessons about love, responsibility, and the nature of adult behavior.\n",
    "\n",
    "On Earth, the Little Prince meets various creatures, including a fox, who teaches him about relationships and the importance of taming, which means building ties with others. The fox's famous line, \"You become responsible, forever, for what you have tamed,\" resonates with the Prince's feelings for his rose.\n",
    "\n",
    "Ultimately, the Little Prince realizes that the essence of life is often invisible and can only be seen with the heart. After sharing his wisdom with the pilot, he prepares to return to his asteroid and his beloved rose. The story concludes with the pilot reflecting on the lessons learned from the Little Prince and the enduring impact of their friendship.\n",
    "\n",
    "The narrative is a beautifully simple yet profound exploration of love, loss, and the importance of seeing beyond the surface of things.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b83f4dd",
   "metadata": {},
   "source": [
    "### 인코딩 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5529fa0",
   "metadata": {},
   "source": [
    "### 토큰화 + 정제/정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5b2d1181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['little', 'prince', 'written', 'antoine', 'saint-exupéry', 'poetic', 'tale', 'young', 'prince', 'travels', 'home', 'planet', 'earth'], ['story', 'begins', 'pilot', 'stranded', 'sahara', 'desert', 'plane', 'crashes'], ['trying', 'fix', 'plane', 'meets', 'mysterious', 'young', 'boy', 'little', 'prince'], ['little', 'prince', 'comes', 'small', 'asteroid', 'called', 'b-612', 'lives', 'alone', 'rose', 'loves', 'deeply'], ['recounts', 'journey', 'pilot', 'describing', 'visits', 'several', 'planets'], ['planet', 'inhabited', 'different', 'character', 'king', 'vain', 'man', 'drunkard', 'businessman', 'geographer', 'fox'], ['encounters', 'prince', 'learns', 'valuable', 'lessons', 'love', 'responsibility', 'nature', 'adult', 'behavior'], ['earth', 'little', 'prince', 'meets', 'various', 'creatures', 'including', 'fox', 'teaches', 'relationships', 'importance', 'taming', 'means', 'building', 'ties', 'others'], ['fox', 'famous', 'line', 'become', 'responsible', 'forever', 'tamed', 'resonates', 'prince', 'feelings', 'rose'], ['ultimately', 'little', 'prince', 'realizes', 'essence', 'life', 'often', 'invisible', 'seen', 'heart'], ['sharing', 'wisdom', 'pilot', 'prepares', 'return', 'asteroid', 'beloved', 'rose'], ['story', 'concludes', 'pilot', 'reflecting', 'lessons', 'learned', 'little', 'prince', 'enduring', 'impact', 'friendship'], ['narrative', 'beautifully', 'simple', 'yet', 'profound', 'exploration', 'love', 'loss', 'importance', 'seeing', 'beyond', 'surface', 'things']]\n",
      "============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================\n",
      "{'little': 6, 'prince': 9, 'written': 1, 'antoine': 1, 'saint-exupéry': 1, 'poetic': 1, 'tale': 1, 'young': 2, 'travels': 1, 'home': 1, 'planet': 2, 'earth': 2, 'story': 2, 'begins': 1, 'pilot': 4, 'stranded': 1, 'sahara': 1, 'desert': 1, 'plane': 2, 'crashes': 1, 'trying': 1, 'fix': 1, 'meets': 2, 'mysterious': 1, 'boy': 1, 'comes': 1, 'small': 1, 'asteroid': 2, 'called': 1, 'b-612': 1, 'lives': 1, 'alone': 1, 'rose': 3, 'loves': 1, 'deeply': 1, 'recounts': 1, 'journey': 1, 'describing': 1, 'visits': 1, 'several': 1, 'planets': 1, 'inhabited': 1, 'different': 1, 'character': 1, 'king': 1, 'vain': 1, 'man': 1, 'drunkard': 1, 'businessman': 1, 'geographer': 1, 'fox': 3, 'encounters': 1, 'learns': 1, 'valuable': 1, 'lessons': 2, 'love': 2, 'responsibility': 1, 'nature': 1, 'adult': 1, 'behavior': 1, 'various': 1, 'creatures': 1, 'including': 1, 'teaches': 1, 'relationships': 1, 'importance': 2, 'taming': 1, 'means': 1, 'building': 1, 'ties': 1, 'others': 1, 'famous': 1, 'line': 1, 'become': 1, 'responsible': 1, 'forever': 1, 'tamed': 1, 'resonates': 1, 'feelings': 1, 'ultimately': 1, 'realizes': 1, 'essence': 1, 'life': 1, 'often': 1, 'invisible': 1, 'seen': 1, 'heart': 1, 'sharing': 1, 'wisdom': 1, 'prepares': 1, 'return': 1, 'beloved': 1, 'concludes': 1, 'reflecting': 1, 'learned': 1, 'enduring': 1, 'impact': 1, 'friendship': 1, 'narrative': 1, 'beautifully': 1, 'simple': 1, 'yet': 1, 'profound': 1, 'exploration': 1, 'loss': 1, 'seeing': 1, 'beyond': 1, 'surface': 1, 'things': 1}\n"
     ]
    }
   ],
   "source": [
    "# 오늘 배운 내용 핵심 정리, 모든 핵심 개념이 들어가 있는 예제 -> 무조건 외우는 코드\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "# from collections import Counter\n",
    "\n",
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "# print(sentences)\n",
    "\n",
    "# 영어 불용어 리스트\n",
    "en_stopwords = stopwords.words('english')\n",
    "# print(en_stopwords)\n",
    "\n",
    "# 단어사전 (key=단어, value=빈도)\n",
    "vocab = {}\n",
    "\n",
    "# 토큰화/정제/정규화 처리 결과\n",
    "preprocessed_sentences = []\n",
    "\n",
    "# 토큰만큼 반복\n",
    "for sentence in sentences:\n",
    "    # 대소문자 정규화 (소문자 변환)\n",
    "    sentence = sentence.lower()\n",
    "    # 단어 토큰화\n",
    "    tokens = word_tokenize(sentence)\n",
    "    # 불용어 제거\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    # 단어 길이가 2 이하이면 제거\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    \n",
    "    # 반복해서 vocab에 존재하지 않을 때는 1로 초기화\n",
    "    # 존재할 경우 하나의 개수를 올림\n",
    "\n",
    "    # 빈도수 측정\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = 1\n",
    "        else:\n",
    "            vocab[token] += 1\n",
    "\n",
    "    # 토큰화/정제/정규화 처리 결과 저장\n",
    "    preprocessed_sentences.append(tokens)\n",
    "\n",
    "print(preprocessed_sentences)\n",
    "print(\"===\"*500)\n",
    "print(vocab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceaccd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# 강사님이 설명해주는 코드(위 동일한 문제)\\nfrom nltk.tokenize import sent_tokenize, word_tokenize\\nfrom nltk.corpus import stopwords\\n\\n# 문장 토큰화\\nsentences = sent_tokenize(raw_text)\\n\\n# 영어 불용어 리스트\\nen_stopwords = stopwords.words(\\'english\\')\\n\\n# 단어사전 (key=단어, value=빈도)\\nvocab = {}\\n\\n# 토큰화/정제/정규화 처리 결과\\npreprocessed_sentences = []\\n\\n# 토큰만큼 반복\\nfor sentence in sentences:\\n    # 대소문자 정규화 (소문자 변환)\\n    sentence = sentence.lower()\\n    # 단어 토큰화\\n    tokens = word_tokenize(sentence)\\n    # 불용어 제거\\n    tokens = [token for token in tokens if token not in en_stopwords]\\n    # 단어 길이가 2 이하이면 제거\\n    tokens = [token for token in tokens if len(token) > 2]\\n\\n    # 빈도수 측정\\n    for token in tokens:\\n        if token not in vocab:\\n            vocab[token] = 1\\n        else:\\n            vocab[token] += 1\\n\\n    # 토큰화/정제/정규화 처리 결과 저장\\n    preprocessed_sentences.append(token)\\n\\nprint(preprocessed_sentences)\\nprint(\"===\"*500)\\nprint(vocab)\\n'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# 강사님이 설명해주는 코드(위 동일한 문제)\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# 문장 토큰화\n",
    "sentences = sent_tokenize(raw_text)\n",
    "\n",
    "# 영어 불용어 리스트\n",
    "en_stopwords = stopwords.words('english')\n",
    "\n",
    "# 단어사전 (key=단어, value=빈도)\n",
    "vocab = {}\n",
    "\n",
    "# 토큰화/정제/정규화 처리 결과\n",
    "preprocessed_sentences = []\n",
    "\n",
    "# 토큰만큼 반복\n",
    "for sentence in sentences:\n",
    "    # 대소문자 정규화 (소문자 변환)\n",
    "    sentence = sentence.lower()\n",
    "    # 단어 토큰화\n",
    "    tokens = word_tokenize(sentence)\n",
    "    # 불용어 제거\n",
    "    tokens = [token for token in tokens if token not in en_stopwords]\n",
    "    # 단어 길이가 2 이하이면 제거\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    \n",
    "    # 빈도수 측정\n",
    "    for token in tokens:\n",
    "        if token not in vocab:\n",
    "            vocab[token] = 1\n",
    "        else:\n",
    "            vocab[token] += 1\n",
    "\n",
    "    # 토큰화/정제/정규화 처리 결과 저장\n",
    "    preprocessed_sentences.append(tokens)\n",
    "\n",
    "print(preprocessed_sentences)\n",
    "print(\"===\"*500)\n",
    "print(vocab)\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ec5b5a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f02f9e",
   "metadata": {},
   "source": [
    "##### 빈도수 기반 정제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94c3cfcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nlambda 함수 기억하지..?\\ndef lambda(item):\\n    return item[1]\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "lambda 함수 기억하지..?\n",
    "def lambda(item):\n",
    "    return item[1]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2800e94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('prince', 9),\n",
       " ('little', 6),\n",
       " ('pilot', 4),\n",
       " ('rose', 3),\n",
       " ('fox', 3),\n",
       " ('young', 2),\n",
       " ('planet', 2),\n",
       " ('earth', 2),\n",
       " ('story', 2),\n",
       " ('plane', 2),\n",
       " ('meets', 2),\n",
       " ('asteroid', 2),\n",
       " ('lessons', 2),\n",
       " ('love', 2),\n",
       " ('importance', 2),\n",
       " ('written', 1),\n",
       " ('antoine', 1),\n",
       " ('saint-exupéry', 1),\n",
       " ('poetic', 1),\n",
       " ('tale', 1),\n",
       " ('travels', 1),\n",
       " ('home', 1),\n",
       " ('begins', 1),\n",
       " ('stranded', 1),\n",
       " ('sahara', 1),\n",
       " ('desert', 1),\n",
       " ('crashes', 1),\n",
       " ('trying', 1),\n",
       " ('fix', 1),\n",
       " ('mysterious', 1),\n",
       " ('boy', 1),\n",
       " ('comes', 1),\n",
       " ('small', 1),\n",
       " ('called', 1),\n",
       " ('b-612', 1),\n",
       " ('lives', 1),\n",
       " ('alone', 1),\n",
       " ('loves', 1),\n",
       " ('deeply', 1),\n",
       " ('recounts', 1),\n",
       " ('journey', 1),\n",
       " ('describing', 1),\n",
       " ('visits', 1),\n",
       " ('several', 1),\n",
       " ('planets', 1),\n",
       " ('inhabited', 1),\n",
       " ('different', 1),\n",
       " ('character', 1),\n",
       " ('king', 1),\n",
       " ('vain', 1),\n",
       " ('man', 1),\n",
       " ('drunkard', 1),\n",
       " ('businessman', 1),\n",
       " ('geographer', 1),\n",
       " ('encounters', 1),\n",
       " ('learns', 1),\n",
       " ('valuable', 1),\n",
       " ('responsibility', 1),\n",
       " ('nature', 1),\n",
       " ('adult', 1),\n",
       " ('behavior', 1),\n",
       " ('various', 1),\n",
       " ('creatures', 1),\n",
       " ('including', 1),\n",
       " ('teaches', 1),\n",
       " ('relationships', 1),\n",
       " ('taming', 1),\n",
       " ('means', 1),\n",
       " ('building', 1),\n",
       " ('ties', 1),\n",
       " ('others', 1),\n",
       " ('famous', 1),\n",
       " ('line', 1),\n",
       " ('become', 1),\n",
       " ('responsible', 1),\n",
       " ('forever', 1),\n",
       " ('tamed', 1),\n",
       " ('resonates', 1),\n",
       " ('feelings', 1),\n",
       " ('ultimately', 1),\n",
       " ('realizes', 1),\n",
       " ('essence', 1),\n",
       " ('life', 1),\n",
       " ('often', 1),\n",
       " ('invisible', 1),\n",
       " ('seen', 1),\n",
       " ('heart', 1),\n",
       " ('sharing', 1),\n",
       " ('wisdom', 1),\n",
       " ('prepares', 1),\n",
       " ('return', 1),\n",
       " ('beloved', 1),\n",
       " ('concludes', 1),\n",
       " ('reflecting', 1),\n",
       " ('learned', 1),\n",
       " ('enduring', 1),\n",
       " ('impact', 1),\n",
       " ('friendship', 1),\n",
       " ('narrative', 1),\n",
       " ('beautifully', 1),\n",
       " ('simple', 1),\n",
       " ('yet', 1),\n",
       " ('profound', 1),\n",
       " ('exploration', 1),\n",
       " ('loss', 1),\n",
       " ('seeing', 1),\n",
       " ('beyond', 1),\n",
       " ('surface', 1),\n",
       " ('things', 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 빈도수 기반 역순 정렬 → 가장 많이 나온 애들이 인덱스 작은순\n",
    "vocab_sorted = sorted(vocab.items(), key=lambda item: item[1], reverse=True)\n",
    "vocab_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2479be47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15,\n",
       " 'written': 16,\n",
       " 'antoine': 17,\n",
       " 'saint-exupéry': 18,\n",
       " 'poetic': 19,\n",
       " 'tale': 20,\n",
       " 'travels': 21,\n",
       " 'home': 22,\n",
       " 'begins': 23,\n",
       " 'stranded': 24,\n",
       " 'sahara': 25,\n",
       " 'desert': 26,\n",
       " 'crashes': 27,\n",
       " 'trying': 28,\n",
       " 'fix': 29,\n",
       " 'mysterious': 30,\n",
       " 'boy': 31,\n",
       " 'comes': 32,\n",
       " 'small': 33,\n",
       " 'called': 34,\n",
       " 'b-612': 35,\n",
       " 'lives': 36,\n",
       " 'alone': 37,\n",
       " 'loves': 38,\n",
       " 'deeply': 39,\n",
       " 'recounts': 40,\n",
       " 'journey': 41,\n",
       " 'describing': 42,\n",
       " 'visits': 43,\n",
       " 'several': 44,\n",
       " 'planets': 45,\n",
       " 'inhabited': 46,\n",
       " 'different': 47,\n",
       " 'character': 48,\n",
       " 'king': 49,\n",
       " 'vain': 50,\n",
       " 'man': 51,\n",
       " 'drunkard': 52,\n",
       " 'businessman': 53,\n",
       " 'geographer': 54,\n",
       " 'encounters': 55,\n",
       " 'learns': 56,\n",
       " 'valuable': 57,\n",
       " 'responsibility': 58,\n",
       " 'nature': 59,\n",
       " 'adult': 60,\n",
       " 'behavior': 61,\n",
       " 'various': 62,\n",
       " 'creatures': 63,\n",
       " 'including': 64,\n",
       " 'teaches': 65,\n",
       " 'relationships': 66,\n",
       " 'taming': 67,\n",
       " 'means': 68,\n",
       " 'building': 69,\n",
       " 'ties': 70,\n",
       " 'others': 71,\n",
       " 'famous': 72,\n",
       " 'line': 73,\n",
       " 'become': 74,\n",
       " 'responsible': 75,\n",
       " 'forever': 76,\n",
       " 'tamed': 77,\n",
       " 'resonates': 78,\n",
       " 'feelings': 79,\n",
       " 'ultimately': 80,\n",
       " 'realizes': 81,\n",
       " 'essence': 82,\n",
       " 'life': 83,\n",
       " 'often': 84,\n",
       " 'invisible': 85,\n",
       " 'seen': 86,\n",
       " 'heart': 87,\n",
       " 'sharing': 88,\n",
       " 'wisdom': 89,\n",
       " 'prepares': 90,\n",
       " 'return': 91,\n",
       " 'beloved': 92,\n",
       " 'concludes': 93,\n",
       " 'reflecting': 94,\n",
       " 'learned': 95,\n",
       " 'enduring': 96,\n",
       " 'impact': 97,\n",
       " 'friendship': 98,\n",
       " 'narrative': 99,\n",
       " 'beautifully': 100,\n",
       " 'simple': 101,\n",
       " 'yet': 102,\n",
       " 'profound': 103,\n",
       " 'exploration': 104,\n",
       " 'loss': 105,\n",
       " 'seeing': 106,\n",
       " 'beyond': 107,\n",
       " 'surface': 108,\n",
       " 'things': 109}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 단어사전 생성1 (key=단어, value=인덱스)\n",
    "# → 튜플 형태 위 데이터를 리스트컴프리헨션을 사용해서 vocab 기반으로 만들어주자!\n",
    "# → 빈도수가 높은 애가 새로운 낮은 인덱스를 얻는 새로운 사전이 생성되었다.\n",
    "word_to_idx = {word: i+1 for i, (word, cnst) in enumerate(vocab_sorted)}\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7ab076bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'prince',\n",
       " 2: 'little',\n",
       " 3: 'pilot',\n",
       " 4: 'rose',\n",
       " 5: 'fox',\n",
       " 6: 'young',\n",
       " 7: 'planet',\n",
       " 8: 'earth',\n",
       " 9: 'story',\n",
       " 10: 'plane',\n",
       " 11: 'meets',\n",
       " 12: 'asteroid',\n",
       " 13: 'lessons',\n",
       " 14: 'love',\n",
       " 15: 'importance',\n",
       " 16: 'written',\n",
       " 17: 'antoine',\n",
       " 18: 'saint-exupéry',\n",
       " 19: 'poetic',\n",
       " 20: 'tale',\n",
       " 21: 'travels',\n",
       " 22: 'home',\n",
       " 23: 'begins',\n",
       " 24: 'stranded',\n",
       " 25: 'sahara',\n",
       " 26: 'desert',\n",
       " 27: 'crashes',\n",
       " 28: 'trying',\n",
       " 29: 'fix',\n",
       " 30: 'mysterious',\n",
       " 31: 'boy',\n",
       " 32: 'comes',\n",
       " 33: 'small',\n",
       " 34: 'called',\n",
       " 35: 'b-612',\n",
       " 36: 'lives',\n",
       " 37: 'alone',\n",
       " 38: 'loves',\n",
       " 39: 'deeply',\n",
       " 40: 'recounts',\n",
       " 41: 'journey',\n",
       " 42: 'describing',\n",
       " 43: 'visits',\n",
       " 44: 'several',\n",
       " 45: 'planets',\n",
       " 46: 'inhabited',\n",
       " 47: 'different',\n",
       " 48: 'character',\n",
       " 49: 'king',\n",
       " 50: 'vain',\n",
       " 51: 'man',\n",
       " 52: 'drunkard',\n",
       " 53: 'businessman',\n",
       " 54: 'geographer',\n",
       " 55: 'encounters',\n",
       " 56: 'learns',\n",
       " 57: 'valuable',\n",
       " 58: 'responsibility',\n",
       " 59: 'nature',\n",
       " 60: 'adult',\n",
       " 61: 'behavior',\n",
       " 62: 'various',\n",
       " 63: 'creatures',\n",
       " 64: 'including',\n",
       " 65: 'teaches',\n",
       " 66: 'relationships',\n",
       " 67: 'taming',\n",
       " 68: 'means',\n",
       " 69: 'building',\n",
       " 70: 'ties',\n",
       " 71: 'others',\n",
       " 72: 'famous',\n",
       " 73: 'line',\n",
       " 74: 'become',\n",
       " 75: 'responsible',\n",
       " 76: 'forever',\n",
       " 77: 'tamed',\n",
       " 78: 'resonates',\n",
       " 79: 'feelings',\n",
       " 80: 'ultimately',\n",
       " 81: 'realizes',\n",
       " 82: 'essence',\n",
       " 83: 'life',\n",
       " 84: 'often',\n",
       " 85: 'invisible',\n",
       " 86: 'seen',\n",
       " 87: 'heart',\n",
       " 88: 'sharing',\n",
       " 89: 'wisdom',\n",
       " 90: 'prepares',\n",
       " 91: 'return',\n",
       " 92: 'beloved',\n",
       " 93: 'concludes',\n",
       " 94: 'reflecting',\n",
       " 95: 'learned',\n",
       " 96: 'enduring',\n",
       " 97: 'impact',\n",
       " 98: 'friendship',\n",
       " 99: 'narrative',\n",
       " 100: 'beautifully',\n",
       " 101: 'simple',\n",
       " 102: 'yet',\n",
       " 103: 'profound',\n",
       " 104: 'exploration',\n",
       " 105: 'loss',\n",
       " 106: 'seeing',\n",
       " 107: 'beyond',\n",
       " 108: 'surface',\n",
       " 109: 'things'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 인덱스 단어사전 생성2 (key=인덱스, value=단어)\n",
    "idx_to_word = {i+1: word for i, (word, cnt) in enumerate(vocab_sorted)}\n",
    "idx_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec30cf24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 15\n",
    "word_to_idx = {word:index for word, index in word_to_idx.items() if index <= vocab_size}\n",
    "\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "57c14ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n지금까지의 과정, 빈도수를 기반으로 사전을(단어, 인덱스) 만들고 (전처리) 그리고 빈도수가 낮은애들 1 → 노이즈로 간주해서 잘라냈다. 문서에 그닥 중요하지 않다고 해석하고 과정을 진행하는 것으로 해석\\n그럼 잘라진 단어는 어떻게 이해하죠? → oov 로 처리할 예정\\n'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "지금까지의 과정, 빈도수를 기반으로 사전을(단어, 인덱스) 만들고 (전처리) 그리고 빈도수가 낮은애들 1 → 노이즈로 간주해서 잘라냈다. 문서에 그닥 중요하지 않다고 해석하고 과정을 진행하는 것으로 해석\n",
    "그럼 잘라진 단어는 어떻게 이해하죠? → oov 로 처리할 예정\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba17b4d",
   "metadata": {},
   "source": [
    "### OOV 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597f2ec2",
   "metadata": {},
   "source": [
    "**OOV(Out of vocabulary)** : 단어사전에 정의되지 않은 단어를 가리키는 키워드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c15c477d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prince': 1,\n",
       " 'little': 2,\n",
       " 'pilot': 3,\n",
       " 'rose': 4,\n",
       " 'fox': 5,\n",
       " 'young': 6,\n",
       " 'planet': 7,\n",
       " 'earth': 8,\n",
       " 'story': 9,\n",
       " 'plane': 10,\n",
       " 'meets': 11,\n",
       " 'asteroid': 12,\n",
       " 'lessons': 13,\n",
       " 'love': 14,\n",
       " 'importance': 15,\n",
       " 'OOV': 16}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_idx['OOV'] = len(word_to_idx) + 1\n",
    "word_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759efb1b",
   "metadata": {},
   "source": [
    "##### 수열처리 (=정수 인코딩)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1071a217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['little', 'prince', 'written', 'antoine', 'saint-exupéry', 'poetic', 'tale', 'young', 'prince', 'travels', 'home', 'planet', 'earth']\n",
      "[2, 1, 16, 16, 16, 16, 16, 6, 1, 16, 16, 7, 8]\n",
      "\n",
      "['story', 'begins', 'pilot', 'stranded', 'sahara', 'desert', 'plane', 'crashes']\n",
      "[9, 16, 3, 16, 16, 16, 10, 16]\n",
      "\n",
      "['trying', 'fix', 'plane', 'meets', 'mysterious', 'young', 'boy', 'little', 'prince']\n",
      "[16, 16, 10, 11, 16, 6, 16, 2, 1]\n",
      "\n",
      "['little', 'prince', 'comes', 'small', 'asteroid', 'called', 'b-612', 'lives', 'alone', 'rose', 'loves', 'deeply']\n",
      "[2, 1, 16, 16, 12, 16, 16, 16, 16, 4, 16, 16]\n",
      "\n",
      "['recounts', 'journey', 'pilot', 'describing', 'visits', 'several', 'planets']\n",
      "[16, 16, 3, 16, 16, 16, 16]\n",
      "\n",
      "['planet', 'inhabited', 'different', 'character', 'king', 'vain', 'man', 'drunkard', 'businessman', 'geographer', 'fox']\n",
      "[7, 16, 16, 16, 16, 16, 16, 16, 16, 16, 5]\n",
      "\n",
      "['encounters', 'prince', 'learns', 'valuable', 'lessons', 'love', 'responsibility', 'nature', 'adult', 'behavior']\n",
      "[16, 1, 16, 16, 13, 14, 16, 16, 16, 16]\n",
      "\n",
      "['earth', 'little', 'prince', 'meets', 'various', 'creatures', 'including', 'fox', 'teaches', 'relationships', 'importance', 'taming', 'means', 'building', 'ties', 'others']\n",
      "[8, 2, 1, 11, 16, 16, 16, 5, 16, 16, 15, 16, 16, 16, 16, 16]\n",
      "\n",
      "['fox', 'famous', 'line', 'become', 'responsible', 'forever', 'tamed', 'resonates', 'prince', 'feelings', 'rose']\n",
      "[5, 16, 16, 16, 16, 16, 16, 16, 1, 16, 4]\n",
      "\n",
      "['ultimately', 'little', 'prince', 'realizes', 'essence', 'life', 'often', 'invisible', 'seen', 'heart']\n",
      "[16, 2, 1, 16, 16, 16, 16, 16, 16, 16]\n",
      "\n",
      "['sharing', 'wisdom', 'pilot', 'prepares', 'return', 'asteroid', 'beloved', 'rose']\n",
      "[16, 16, 3, 16, 16, 12, 16, 4]\n",
      "\n",
      "['story', 'concludes', 'pilot', 'reflecting', 'lessons', 'learned', 'little', 'prince', 'enduring', 'impact', 'friendship']\n",
      "[9, 16, 3, 16, 13, 16, 2, 1, 16, 16, 16]\n",
      "\n",
      "['narrative', 'beautifully', 'simple', 'yet', 'profound', 'exploration', 'love', 'loss', 'importance', 'seeing', 'beyond', 'surface', 'things']\n",
      "[16, 16, 16, 16, 16, 16, 14, 16, 15, 16, 16, 16, 16]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_sentences = []\n",
    "oov_idx = word_to_idx['OOV']\n",
    "\n",
    "for sentence in preprocessed_sentences:\n",
    "    encoded_sentence = [word_to_idx.get(token, oov_idx) for token in sentence]\n",
    "    print(sentence)\n",
    "    print(encoded_sentence)\n",
    "    print()\n",
    "    encoded_sentences.append(encoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b05906",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f6f559",
   "metadata": {},
   "source": [
    "### keras Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bae704ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f04cb74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " 'prince': 2,\n",
       " 'little': 3,\n",
       " 'pilot': 4,\n",
       " 'rose': 5,\n",
       " 'fox': 6,\n",
       " 'young': 7,\n",
       " 'planet': 8,\n",
       " 'earth': 9,\n",
       " 'story': 10,\n",
       " 'plane': 11,\n",
       " 'meets': 12,\n",
       " 'asteroid': 13,\n",
       " 'lessons': 14,\n",
       " 'love': 15,\n",
       " 'importance': 16,\n",
       " 'written': 17,\n",
       " 'antoine': 18,\n",
       " 'saint-exupéry': 19,\n",
       " 'poetic': 20,\n",
       " 'tale': 21,\n",
       " 'travels': 22,\n",
       " 'home': 23,\n",
       " 'begins': 24,\n",
       " 'stranded': 25,\n",
       " 'sahara': 26,\n",
       " 'desert': 27,\n",
       " 'crashes': 28,\n",
       " 'trying': 29,\n",
       " 'fix': 30,\n",
       " 'mysterious': 31,\n",
       " 'boy': 32,\n",
       " 'comes': 33,\n",
       " 'small': 34,\n",
       " 'called': 35,\n",
       " 'b-612': 36,\n",
       " 'lives': 37,\n",
       " 'alone': 38,\n",
       " 'loves': 39,\n",
       " 'deeply': 40,\n",
       " 'recounts': 41,\n",
       " 'journey': 42,\n",
       " 'describing': 43,\n",
       " 'visits': 44,\n",
       " 'several': 45,\n",
       " 'planets': 46,\n",
       " 'inhabited': 47,\n",
       " 'different': 48,\n",
       " 'character': 49,\n",
       " 'king': 50,\n",
       " 'vain': 51,\n",
       " 'man': 52,\n",
       " 'drunkard': 53,\n",
       " 'businessman': 54,\n",
       " 'geographer': 55,\n",
       " 'encounters': 56,\n",
       " 'learns': 57,\n",
       " 'valuable': 58,\n",
       " 'responsibility': 59,\n",
       " 'nature': 60,\n",
       " 'adult': 61,\n",
       " 'behavior': 62,\n",
       " 'various': 63,\n",
       " 'creatures': 64,\n",
       " 'including': 65,\n",
       " 'teaches': 66,\n",
       " 'relationships': 67,\n",
       " 'taming': 68,\n",
       " 'means': 69,\n",
       " 'building': 70,\n",
       " 'ties': 71,\n",
       " 'others': 72,\n",
       " 'famous': 73,\n",
       " 'line': 74,\n",
       " 'become': 75,\n",
       " 'responsible': 76,\n",
       " 'forever': 77,\n",
       " 'tamed': 78,\n",
       " 'resonates': 79,\n",
       " 'feelings': 80,\n",
       " 'ultimately': 81,\n",
       " 'realizes': 82,\n",
       " 'essence': 83,\n",
       " 'life': 84,\n",
       " 'often': 85,\n",
       " 'invisible': 86,\n",
       " 'seen': 87,\n",
       " 'heart': 88,\n",
       " 'sharing': 89,\n",
       " 'wisdom': 90,\n",
       " 'prepares': 91,\n",
       " 'return': 92,\n",
       " 'beloved': 93,\n",
       " 'concludes': 94,\n",
       " 'reflecting': 95,\n",
       " 'learned': 96,\n",
       " 'enduring': 97,\n",
       " 'impact': 98,\n",
       " 'friendship': 99,\n",
       " 'narrative': 100,\n",
       " 'beautifully': 101,\n",
       " 'simple': 102,\n",
       " 'yet': 103,\n",
       " 'profound': 104,\n",
       " 'exploration': 105,\n",
       " 'loss': 106,\n",
       " 'seeing': 107,\n",
       " 'beyond': 108,\n",
       " 'surface': 109,\n",
       " 'things': 110}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words=15, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(preprocessed_sentences)\n",
    "tokenizer.word_index    # corpus의 모든 단어를 대상으로 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e790a5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '<OOV>',\n",
       " 2: 'prince',\n",
       " 3: 'little',\n",
       " 4: 'pilot',\n",
       " 5: 'rose',\n",
       " 6: 'fox',\n",
       " 7: 'young',\n",
       " 8: 'planet',\n",
       " 9: 'earth',\n",
       " 10: 'story',\n",
       " 11: 'plane',\n",
       " 12: 'meets',\n",
       " 13: 'asteroid',\n",
       " 14: 'lessons',\n",
       " 15: 'love',\n",
       " 16: 'importance',\n",
       " 17: 'written',\n",
       " 18: 'antoine',\n",
       " 19: 'saint-exupéry',\n",
       " 20: 'poetic',\n",
       " 21: 'tale',\n",
       " 22: 'travels',\n",
       " 23: 'home',\n",
       " 24: 'begins',\n",
       " 25: 'stranded',\n",
       " 26: 'sahara',\n",
       " 27: 'desert',\n",
       " 28: 'crashes',\n",
       " 29: 'trying',\n",
       " 30: 'fix',\n",
       " 31: 'mysterious',\n",
       " 32: 'boy',\n",
       " 33: 'comes',\n",
       " 34: 'small',\n",
       " 35: 'called',\n",
       " 36: 'b-612',\n",
       " 37: 'lives',\n",
       " 38: 'alone',\n",
       " 39: 'loves',\n",
       " 40: 'deeply',\n",
       " 41: 'recounts',\n",
       " 42: 'journey',\n",
       " 43: 'describing',\n",
       " 44: 'visits',\n",
       " 45: 'several',\n",
       " 46: 'planets',\n",
       " 47: 'inhabited',\n",
       " 48: 'different',\n",
       " 49: 'character',\n",
       " 50: 'king',\n",
       " 51: 'vain',\n",
       " 52: 'man',\n",
       " 53: 'drunkard',\n",
       " 54: 'businessman',\n",
       " 55: 'geographer',\n",
       " 56: 'encounters',\n",
       " 57: 'learns',\n",
       " 58: 'valuable',\n",
       " 59: 'responsibility',\n",
       " 60: 'nature',\n",
       " 61: 'adult',\n",
       " 62: 'behavior',\n",
       " 63: 'various',\n",
       " 64: 'creatures',\n",
       " 65: 'including',\n",
       " 66: 'teaches',\n",
       " 67: 'relationships',\n",
       " 68: 'taming',\n",
       " 69: 'means',\n",
       " 70: 'building',\n",
       " 71: 'ties',\n",
       " 72: 'others',\n",
       " 73: 'famous',\n",
       " 74: 'line',\n",
       " 75: 'become',\n",
       " 76: 'responsible',\n",
       " 77: 'forever',\n",
       " 78: 'tamed',\n",
       " 79: 'resonates',\n",
       " 80: 'feelings',\n",
       " 81: 'ultimately',\n",
       " 82: 'realizes',\n",
       " 83: 'essence',\n",
       " 84: 'life',\n",
       " 85: 'often',\n",
       " 86: 'invisible',\n",
       " 87: 'seen',\n",
       " 88: 'heart',\n",
       " 89: 'sharing',\n",
       " 90: 'wisdom',\n",
       " 91: 'prepares',\n",
       " 92: 'return',\n",
       " 93: 'beloved',\n",
       " 94: 'concludes',\n",
       " 95: 'reflecting',\n",
       " 96: 'learned',\n",
       " 97: 'enduring',\n",
       " 98: 'impact',\n",
       " 99: 'friendship',\n",
       " 100: 'narrative',\n",
       " 101: 'beautifully',\n",
       " 102: 'simple',\n",
       " 103: 'yet',\n",
       " 104: 'profound',\n",
       " 105: 'exploration',\n",
       " 106: 'loss',\n",
       " 107: 'seeing',\n",
       " 108: 'beyond',\n",
       " 109: 'surface',\n",
       " 110: 'things'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "666dfbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('little', 6),\n",
       "             ('prince', 9),\n",
       "             ('written', 1),\n",
       "             ('antoine', 1),\n",
       "             ('saint-exupéry', 1),\n",
       "             ('poetic', 1),\n",
       "             ('tale', 1),\n",
       "             ('young', 2),\n",
       "             ('travels', 1),\n",
       "             ('home', 1),\n",
       "             ('planet', 2),\n",
       "             ('earth', 2),\n",
       "             ('story', 2),\n",
       "             ('begins', 1),\n",
       "             ('pilot', 4),\n",
       "             ('stranded', 1),\n",
       "             ('sahara', 1),\n",
       "             ('desert', 1),\n",
       "             ('plane', 2),\n",
       "             ('crashes', 1),\n",
       "             ('trying', 1),\n",
       "             ('fix', 1),\n",
       "             ('meets', 2),\n",
       "             ('mysterious', 1),\n",
       "             ('boy', 1),\n",
       "             ('comes', 1),\n",
       "             ('small', 1),\n",
       "             ('asteroid', 2),\n",
       "             ('called', 1),\n",
       "             ('b-612', 1),\n",
       "             ('lives', 1),\n",
       "             ('alone', 1),\n",
       "             ('rose', 3),\n",
       "             ('loves', 1),\n",
       "             ('deeply', 1),\n",
       "             ('recounts', 1),\n",
       "             ('journey', 1),\n",
       "             ('describing', 1),\n",
       "             ('visits', 1),\n",
       "             ('several', 1),\n",
       "             ('planets', 1),\n",
       "             ('inhabited', 1),\n",
       "             ('different', 1),\n",
       "             ('character', 1),\n",
       "             ('king', 1),\n",
       "             ('vain', 1),\n",
       "             ('man', 1),\n",
       "             ('drunkard', 1),\n",
       "             ('businessman', 1),\n",
       "             ('geographer', 1),\n",
       "             ('fox', 3),\n",
       "             ('encounters', 1),\n",
       "             ('learns', 1),\n",
       "             ('valuable', 1),\n",
       "             ('lessons', 2),\n",
       "             ('love', 2),\n",
       "             ('responsibility', 1),\n",
       "             ('nature', 1),\n",
       "             ('adult', 1),\n",
       "             ('behavior', 1),\n",
       "             ('various', 1),\n",
       "             ('creatures', 1),\n",
       "             ('including', 1),\n",
       "             ('teaches', 1),\n",
       "             ('relationships', 1),\n",
       "             ('importance', 2),\n",
       "             ('taming', 1),\n",
       "             ('means', 1),\n",
       "             ('building', 1),\n",
       "             ('ties', 1),\n",
       "             ('others', 1),\n",
       "             ('famous', 1),\n",
       "             ('line', 1),\n",
       "             ('become', 1),\n",
       "             ('responsible', 1),\n",
       "             ('forever', 1),\n",
       "             ('tamed', 1),\n",
       "             ('resonates', 1),\n",
       "             ('feelings', 1),\n",
       "             ('ultimately', 1),\n",
       "             ('realizes', 1),\n",
       "             ('essence', 1),\n",
       "             ('life', 1),\n",
       "             ('often', 1),\n",
       "             ('invisible', 1),\n",
       "             ('seen', 1),\n",
       "             ('heart', 1),\n",
       "             ('sharing', 1),\n",
       "             ('wisdom', 1),\n",
       "             ('prepares', 1),\n",
       "             ('return', 1),\n",
       "             ('beloved', 1),\n",
       "             ('concludes', 1),\n",
       "             ('reflecting', 1),\n",
       "             ('learned', 1),\n",
       "             ('enduring', 1),\n",
       "             ('impact', 1),\n",
       "             ('friendship', 1),\n",
       "             ('narrative', 1),\n",
       "             ('beautifully', 1),\n",
       "             ('simple', 1),\n",
       "             ('yet', 1),\n",
       "             ('profound', 1),\n",
       "             ('exploration', 1),\n",
       "             ('loss', 1),\n",
       "             ('seeing', 1),\n",
       "             ('beyond', 1),\n",
       "             ('surface', 1),\n",
       "             ('things', 1)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_counts    # corpus의 모든 단어를 대상으로 빈도수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a26ba34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 2, 1, 1, 1, 1, 1, 7, 2, 1, 1, 8, 9],\n",
       " [10, 1, 4, 1, 1, 1, 11, 1],\n",
       " [1, 1, 11, 12, 1, 7, 1, 3, 2],\n",
       " [3, 2, 1, 1, 13, 1, 1, 1, 1, 5, 1, 1],\n",
       " [1, 1, 4, 1, 1, 1, 1],\n",
       " [8, 1, 1, 1, 1, 1, 1, 1, 1, 1, 6],\n",
       " [1, 2, 1, 1, 14, 1, 1, 1, 1, 1],\n",
       " [9, 3, 2, 12, 1, 1, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       " [6, 1, 1, 1, 1, 1, 1, 1, 2, 1, 5],\n",
       " [1, 3, 2, 1, 1, 1, 1, 1, 1, 1],\n",
       " [1, 1, 4, 1, 1, 13, 1, 5],\n",
       " [10, 1, 4, 1, 14, 1, 3, 2, 1, 1, 1],\n",
       " [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정수 인코딩\n",
    "sequences = tokenizer.texts_to_sequences(preprocessed_sentences)\n",
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd107a72",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2245044112.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mEOS, SOS, Head Token?\u001b[39m\n                   ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "EOS, SOS, Head Token? → 특수 코드를 처리하는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7b0dd6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc75c13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
